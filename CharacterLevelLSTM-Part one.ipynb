{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ6I5Yr8QUtD"
   },
   "source": [
    "### Character-Level Language Model\n",
    "\n",
    "This notebook contains a generative model working at the level of characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I embarked on this task by first downloading the character-level model from My class website, Then, I executed the code using a dataset consisting of Java code files. I also read the article \"The Unreasonable Effectiveness of Recurrent Neural Networks\" linked with Lecture 14. This provided insights into the capabilities and challenges of character-level models. I selected Java code files from the dataset and combined them into one long text file. The dataset contained approximately 10-20K characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RqPkh2KTGUGp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint,rand,seed,normal,permutation,choice\n",
    "\n",
    "import string\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# from torchsummary import summary                   # must install using pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbYPF_0RQw1j"
   },
   "source": [
    "Load a text file. We chose a poem, to see how it did with line breaks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2_zGTaCKGUGs",
    "outputId": "46973f9f-1845-40ff-8287-b68b4eb8556a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of Man's first disobedience, and the fruit\\nOf that forbidden tree whose mortal taste\\nBrought death i\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"Milton_Paradise_Lost.txt\", \"r\") as text_file:\n",
    "    text = text_file.read()\n",
    "\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "java_file1 = 'Othello.java'\n",
    "java_file2 = 'EightPuzzle.java'\n",
    "java_file3 = 'TicTacToe.java'\n",
    "output_file = 'combinedfile.txt'\n",
    "\n",
    "def concatenate_files(file_paths, output_path):\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        for file_path in file_paths:\n",
    "            with open(file_path, 'r') as infile:\n",
    "                outfile.write(infile.read() + \"\\n\")\n",
    "\n",
    "\n",
    "concatenate_files([java_file1, java_file2, java_file3], output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"combinedfile.txt\", \"r\") as text_file:\n",
    "    text = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/*\\n * Othello.java\\n *\\n * Version:\\n *    $Id$\\n *\\n * Revisions:\\n *    &Log$\\n *\\n */\\n\\nimport java.util.*;\\nimport java.awt.*;        \\nimport java.awt.event.*;\\nimport javax.swing.*;\\n\\n/** \\n * This program is the driver for the game of Othello.<br> \\n *\\n * Run the program as one of the following:<br>\\n *     java Othello          (GUI with a default delay time of 1 second)<br>\\n *     java Othello delay    (GUI with a delay of (delay) milliseconds)<br>\\n *     java Othello 0        (GUI with human (Black) vs. machine (White))<br>\\n *     java Othello -delay   (No GUI - run program (delay) times)<br>\\n *\\n * @author     Roxanne Canosa\\n *\\n */\\n\\npublic class Othello extends JPanel \\n{\\n    final static int BLACK = 1;          // Declare state of each square\\n    final static int WHITE = 2;\\n    final static int EMPTY = 0;\\n    final static int OFFBOARD = -1;\\n\\n    Black black = new Black();          // The players\\n    White white = new White();\\n\\n    private Game game = new Game();     // Game state\\n    private javax.swing.Timer timer;\\n    private static int delay;\\n    private static long startTime, stopTime, runTime = 0;\\n    private int turn = BLACK;\\n    private boolean black_done = false; \\n    private boolean white_done = false;\\n    \\n    /**\\n     *  This constructor sets up the initial game configuration, \\n     *  and starts the timer with a default delay of 1 second.\\n     */\\n    public Othello() { this(1000); }\\n\\n    /**\\n     *  This constructor sets up the initial game configuration, \\n     *  and starts the timer with a user specified delay.\\n     *\\n     *  @param    delay    number of milliseconds between player moves\\n     */\\n    public Othello(int delay) {\\n\\n        // Initialize the game state\\n        initGame(game);\\n       \\n        // Run the game with GUI - computer vs. computer using a timer\\n        if (delay > 0) {\\n            setBackground(Color.GREEN);\\n            timer = new javax.swing.Timer(delay, new ActionListener() {\\n                    public void actionPerformed(ActionEvent e) {\\n                        playerMove();\\n                        repaint();\\n                    }\\n                });\\n            \\n            // Create the Start and Stop buttons\\n            JButton start = new JButton(\"Start\"); \\n            start.setBounds(10,20,80,25); \\n            add(start);\\n            start.addActionListener(new ActionListener(){\\n                    public void actionPerformed(ActionEvent evt){\\n                        timer.start();\\n                    }\\n                });\\n\\n            JButton stop = new JButton(\"Stop\"); \\n            stop.setBounds(10,80,80,25); \\n            add(stop);\\n            stop.addActionListener(new ActionListener(){\\n                    public void actionPerformed(ActionEvent evt){\\n                        timer.stop();\\n                    }\\n                });\\n        }\\n\\n        // Run the game with GUI - human vs. computer. \\n        // The human player always plays with the black discs.\\n        if (delay == 0) {\\n            setBackground(Color.GREEN);\\n            addMouseListener( new MouseAdapter() {\\n                    public void mousePressed(MouseEvent evt) {\\n                        // Find out which square was clicked\\n                        int x = evt.getX();\\n                        int y = evt.getY();\\n                        int screenWidth = getWidth();\\n                        int screenHeight = getHeight();\\n                        int column = (x*(game.WIDTH-2))/screenWidth+1;\\n                        int row = (y*(game.HEIGHT-2))/screenHeight+1;\\n                        \\n                        if (!game.legalMove(row,column,BLACK,true)) \\n                           System.out.println(\"Not a legal move - try again!\");\\n                        else {\\n                            game.board[row][column] = BLACK;\\n                            repaint();\\n                            black_done = true;\\n                            for (int i=1; i<game.HEIGHT-1; i++)\\n                                for (int j=1; j<game.WIDTH-1; j++)\\n                                    if (game.legalMove(i,j,BLACK,false) )\\n                                        black_done=false;\\n                            whiteMove();\\n                        }\\n                    }\\n                });\\n        }\\n\\n        // Run the game without the GUI - as many times as specified in delay.\\n        if (delay < 0) {\\n\\n            // Start timing how long it takes to play \"delay\" games\\n            startTime = new Date().getTime();\\n\\n            // Keep track of how many wins each color has\\n            int white_won = 0;\\n            int black_won = 0;\\n            int ties = 0;\\n\\n            // Play a bunch of games!\\n            for (int times=0; times < -delay; times++) {\\n                initGame(game);\\n                boolean done = false;\\n                white_done = false;\\n                black_done = false;\\n         \\n                while (!done) {\\n                    playerMove();\\n                    int bC = 0;\\n                   '"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5000]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvdwU6PeQugU"
   },
   "source": [
    "No normalization will be performed, however,\n",
    "we will run out of RAM if we attempt to\n",
    "use the entire poem as data. We have chosen\n",
    "here to use 10K characters, out of a total\n",
    "of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVfP44ZUGUGs",
    "outputId": "4f393b80-cd76-4f02-a3e7-1c9c5e21ae21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 28640 characters long.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text is {len(text)} characters long.\")\n",
    "\n",
    "size = 10000\n",
    "\n",
    "text = text[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwgjqUe5R0eX"
   },
   "source": [
    "Next we figure out how many distinct characters there are in the text; this\n",
    "will be what is generated at each step of the generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYeHZcdzGUGt",
    "outputId": "ef380ca5-16ff-467a-fc86-5f3719f42b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 82 characters in the text.\n",
      "Character set: ['\\n', ' ', '!', '\"', '$', '&', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '5', '8', ':', ';', '<', '=', '>', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}'].\n"
     ]
    }
   ],
   "source": [
    "chars_in_text = sorted(list(set(text)))\n",
    "\n",
    "num_chars = len(chars_in_text)\n",
    "\n",
    "print(f'There are {num_chars} characters in the text.')\n",
    "\n",
    "\n",
    "print(f'Character set: {chars_in_text}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "gwALsQhiStNT"
   },
   "outputs": [],
   "source": [
    "# Create functions mapping characters to integers and back\n",
    "\n",
    "def char2int(c):\n",
    "    return chars_in_text.index(c)\n",
    "\n",
    "def int2char(i):\n",
    "    return chars_in_text[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68JWvJxdGUGt"
   },
   "source": [
    "As we're going to predict the next character in the sequence at each time step, we'll have to divide each sentence into\n",
    "\n",
    "- Input data\n",
    "    - The last input character should be excluded as it does not need to be fed into the model\n",
    "- Target/Ground Truth Label\n",
    "    - One time-step ahead of the Input data as this will be the \"correct answer\" for the model at each time step corresponding to the input data\n",
    "\n",
    "The sample length is a critical parameter which tells us how much of the source data to ingest at each training step.  You might want to play around with this as one of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYyi7B_IGUGu",
    "outputId": "ee9dab6f-b29d-41e5-a2be-78a32eb6f011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      "/*\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.\n",
      "Target sequence:\n",
      "*\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*\n",
      "\n",
      "Input sequence:\n",
      "*\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*\n",
      "Target sequence:\n",
      "\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "\n",
      "Input sequence:\n",
      "\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "Target sequence:\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "\n",
      "\n",
      "Input sequence:\n",
      " * Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "\n",
      "Target sequence:\n",
      "* Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "i\n",
      "\n",
      "Input sequence:\n",
      "* Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "i\n",
      "Target sequence:\n",
      " Othello.java\n",
      " *\n",
      " * Version:\n",
      " *    $Id$\n",
      " *\n",
      " * Revisions:\n",
      " *    &Log$\n",
      " *\n",
      " */\n",
      "\n",
      "import java.util.*;\n",
      "im\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_len = 100\n",
    "\n",
    "# Creating lists that will hold our input and target sample sequences\n",
    "\n",
    "input_seq_chars = []\n",
    "target_seq_chars = []\n",
    "\n",
    "for k in range(len(text)-sample_len+1):\n",
    "\n",
    "    # Remove last character for input sequence\n",
    "    input_seq_chars.append(text[k:k+sample_len-1])\n",
    "\n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq_chars.append(text[k+1:k+sample_len])\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Input sequence:\\n{input_seq_chars[i]}')\n",
    "    print(f'Target sequence:\\n{target_seq_chars[i]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYT6SCJ9GUGu"
   },
   "source": [
    "Now we can convert our input and target sequences to sequences of integers instead of characters by mapping them using the functions we created above. This will allow us to one-hot-encode our input sequence later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJXQF5NAGUGu",
    "outputId": "74125302-b170-4b2c-d9f8-97076382e5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 8, 0, 1, 8, 1, 39, 72, 60, 57, 64, 64, 67, 12, 62, 53, 74, 53, 0, 1, 8, 0, 1, 8, 1, 45, 57, 70, 71, 61, 67, 66, 19, 0, 1, 8, 1, 1, 1, 1, 4, 33, 56, 4, 0, 1, 8, 0, 1, 8, 1, 41, 57, 74, 61, 71, 61, 67, 66, 71, 19, 0, 1, 8, 1, 1, 1, 1, 5, 36, 67, 59, 4, 0, 1, 8, 0, 1, 8, 13, 0, 0, 61, 65, 68, 67, 70, 72, 1, 62, 53, 74, 53, 12, 73, 72, 61, 64, 12]\n"
     ]
    }
   ],
   "source": [
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(input_seq_chars)):\n",
    "    input_seq.append( [char2int(ch) for ch in input_seq_chars[i]])\n",
    "    target_seq.append([char2int(ch) for ch in target_seq_chars[i]])\n",
    "\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Q5xPFM0GUGu",
    "outputId": "cd14643b-f18b-4397-9541-1fceb596c4f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert an integer into a one-hot encoding of the given size (= number of characters)\n",
    "def int2OneHot(X,size):\n",
    "\n",
    "    def int2OneHot1(x,size=10):\n",
    "        tmp = np.zeros(size)\n",
    "        tmp[int(x)] = 1.0\n",
    "        return tmp\n",
    "\n",
    "    return np.array([ int2OneHot1(x, size) for x in X ]).astype('double')\n",
    "\n",
    "int2OneHot( np.array([ 2,3,1,2,3,4 ]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0v3RGM8AGUGv",
    "outputId": "55840113-66ca-4b5f-e6b5-64d8c49c16cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same thing, but for a list/array of integers\n",
    "\n",
    "def seq2OneHot(seq,size):\n",
    "    return np.array([ int2OneHot(x, size) for x in seq ])\n",
    "\n",
    "seq2OneHot( np.array([[ 2,3,1,2,3,4 ],[ 2,3,1,2,3,4 ],[ 2,3,1,2,3,4 ]]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbTrt7AjGUGv",
    "outputId": "3d839dbb-597a-44c8-c81f-e89a9b55a93b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9901, 99, 82)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our input sequences to one-hot form\n",
    "\n",
    "input_seq = seq2OneHot(input_seq,size=num_chars)\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1KM2AaXGUGv",
    "outputId": "b7532041-b4a6-4a14-b026-39b090383606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9901, 99, 82)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our target sequences to one-hot form\n",
    "\n",
    "target_seq = seq2OneHot(target_seq,size=num_chars)\n",
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEYJ0NE0GUGv"
   },
   "source": [
    "Since we're done with all the data pre-processing, we can now move the data from numpy arrays to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "CcrO5N7RGUGv"
   },
   "outputs": [],
   "source": [
    "input_seq = torch.Tensor(input_seq).type(torch.DoubleTensor)\n",
    "target_seq = torch.Tensor(target_seq).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5NEt539GUGv"
   },
   "source": [
    "Now we will build a data loader to manage the batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhkkAfJVVViF",
    "outputId": "165c3008-fcc8-42b6-901a-805f35fb46c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9901"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Basic_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # return a pair x,y at the index idx in the data set\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "ds = Basic_Dataset(input_seq,target_seq)\n",
    "\n",
    "ds.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FPjzvUbVrAd"
   },
   "source": [
    "Batch size is a hyperparameter that will mostly determine how efficiently you can process the data on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "v4vgBd0jGUGv"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "data_loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wgOsxHYGUGv"
   },
   "source": [
    "Check if a GPU is available and use it if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFwBQZ1uGUGv",
    "outputId": "3242cf1c-56d9-4600-922c-91e3248a86ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6u-fhYkGUGv"
   },
   "source": [
    "The model will use an LSTM layer and a single linear layer to produce a softmax\n",
    "of the next character. Various hyperparameters can be chosen to modify this\n",
    "model.  A messy detail is that two vectors, h0 and c0, have to be created for the hidden state in the LSTM layer (these correspond to the two connections\n",
    "shown in lecture for an LSTM neuron to send to itself in the next time step).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "dzDdSvGAGUGw"
   },
   "outputs": [],
   "source": [
    "from os import device_encoding\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers,dropout):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers,dropout=dropout,batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        hidden_state_size = x.size(0)\n",
    "\n",
    "        x = x.to(torch.double)\n",
    "\n",
    "        h0 = torch.zeros(self.n_layers,hidden_state_size,self.hidden_dim).double().to(device)\n",
    "        c0 = torch.zeros(self.n_layers,hidden_state_size,self.hidden_dim).double().to(device)\n",
    "\n",
    "        self.lstm = self.lstm.double()\n",
    "\n",
    "        self.fc1 = self.fc1.double()\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, (hx,cx) = self.lstm(x, (h0,c0))\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xr571AKQXDQH"
   },
   "source": [
    "Next, we instantiate the model with its hyperparameters, all of which can be\n",
    "changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNUwEsRDGUGw",
    "outputId": "6331a61c-88fe-441c-ed46-1ce08d06d502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (lstm): LSTM(82, 512, batch_first=True, dropout=0.2)\n",
      "  (fc1): Linear(in_features=512, out_features=82, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Model(input_size=num_chars, output_size=num_chars, hidden_dim=512, n_layers=1,dropout=0.2)\n",
    "\n",
    "print(model)\n",
    "\n",
    "model = model.double().to(device)\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDrJKscMXaU0"
   },
   "source": [
    "The following is a minimal training loop. We just track the loss, since accuracy\n",
    "is not the point of a generative model.\n",
    "\n",
    "However, overfitting is very much a problem. You will see that overfitting has occurred when you give as prompt a prefix of the text (say the first line) and in generation it just spits out the text (which it has memorized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "HVClRHtXGUGw",
    "outputId": "9b729a48-5cbf-46cd-f76a-149401ac695a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [14:52<00:00, 59.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x285e7fe50>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    for input_seq_batch,target_seq_batch in data_loader:\n",
    "        input_seq_batch = input_seq_batch.to(device)\n",
    "        target_seq_batch = target_seq_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target_seq_hat = model(input_seq_batch)\n",
    "        loss = loss_fn(target_seq_hat,target_seq_batch.view(-1,num_chars))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuyAwhLPXtGd"
   },
   "source": [
    "The temperature of a softmax function will determine  the relative strength of different probabilities:\n",
    "- As temperature approaches 0, distribution approaches a one-hot with 1 for the max\n",
    "- As temperature increases, it approaches a uniform distribution\n",
    "\n",
    "Generally we want to emphasize the higher probabilities, so we choose\n",
    "a reasonably low temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg7j3CzGQDkf",
    "outputId": "35c12c65-d238-46c7-a812-4478cd0191fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of softmax with temperature.\n",
      "distribution: [0.1, 0.3, 0.6]\n",
      "[1.9287498479637375e-22, 9.3576229688393e-14, 0.9999999999999064]\n",
      "[0.006377460922442302, 0.04712341652466416, 0.9464991225528936]\n",
      "[0.06289001324586753, 0.1709527801977903, 0.7661572065563421]\n",
      "[0.12132647558421489, 0.23631170657656433, 0.6423618178392208]\n",
      "[0.2583896517379799, 0.3155978333128144, 0.4260125149492058]\n",
      "[0.3255767455856355, 0.3321538321280155, 0.3422694222863489]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def softmax_with_temperature(vec, temperature):\n",
    "    sum_exp = sum(math.exp(x/temperature) for x in vec)\n",
    "    return [math.exp(x/temperature)/sum_exp for x in vec]\n",
    "\n",
    "print(\"Example of softmax with temperature.\")\n",
    "dist = [0.1, 0.3, 0.6]\n",
    "print('distribution:',dist)\n",
    "print(softmax_with_temperature(dist,0.01))\n",
    "print(softmax_with_temperature(dist,0.1))\n",
    "print(softmax_with_temperature(dist,0.2))\n",
    "print(softmax_with_temperature(dist,0.3))\n",
    "print(softmax_with_temperature(dist,1))\n",
    "print(softmax_with_temperature(dist,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLlygE7WYigs"
   },
   "source": [
    "Choose a temperature and predict the next character, given a prompt of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kLJX_vFSGUGw",
    "outputId": "91ba9e04-6bbf-4b80-c302-db6fb13dbf55",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 0.3\n",
    "\n",
    "def predict(model, ch):\n",
    "\n",
    "    # only look at last sample_len - 1 characters\n",
    "\n",
    "    ch = ch[-(sample_len - 1):]\n",
    "\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    ch = np.array([char2int(c) for c in ch])\n",
    "    ch = np.array([int2OneHot(ch, num_chars)])\n",
    "    ch = torch.from_numpy(ch).to(device)\n",
    "\n",
    "    out = model(ch)\n",
    "\n",
    "    # take the probability distribution of the last character in the sequence produced by the model\n",
    "    prob = softmax_with_temperature(out[-1],temperature)\n",
    "\n",
    "    # Choosing a character based on the probability distribution, with temperature\n",
    "    char_ind = choice(list(range(num_chars)), p=prob)\n",
    "\n",
    "    return int2char(char_ind)\n",
    "\n",
    "predict(model,\"final static int OFFBOARD = -1;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wThVXlXhYgqt"
   },
   "source": [
    "Now take a prompt and iterate the previous prediction a specified number of times.\n",
    "\n",
    "Prompt is generally taken to be a long sequence randomly selected from the text. You can also try a sequence of words similar to those in the text, but not an exact sequence. It does not have to be the exact length of the data sequences. However, very short prompts tend not to work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "eFcGfQ8VGUGw"
   },
   "outputs": [],
   "source": [
    "def sample(model, out_len, start):\n",
    "    model.eval() # eval mode\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LONowWPkg6bj"
   },
   "source": [
    "Now we will run our model, but with the parameters we have chosen, and\n",
    "10 epochs, you can see that it is getting some idea of words and lines, but\n",
    "it doesn't look like an English poem!\n",
    "\n",
    "Run this for another 100 epochs, and observe that at that point,\n",
    "the network will have simply memorized the poem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra7VOpilGUGw",
    "outputId": "df558ad6-30d1-4840-932a-95e364358acf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "Model : default\n",
      "Changes : Only epoches is increased to 30\n",
      "\n",
      "\n",
      "final static int OFFBOARD = -1;\n",
      "\n",
      "    Black black = new Black();          // The players\n",
      "    White white = new White();\n",
      "\n",
      "    private Game game = new Game();     // Game state\n",
      "    private javax.swing.Timer timer;\n",
      "    private static int delay;\n",
      "    private static long startTime, stopTime, runTime = 0;\n",
      "    private int turn = BLACK;\n",
      "    private boolean black_done = false; \n",
      "    private boolean white_done = false;\n",
      "    \n",
      "    /**\n",
      "     *  This constructor sets up the initial game configuration, \n",
      "     *  and starts the timer with a default delay of 1 second.\n",
      "     */\n",
      "    public Othello() { this(1000); }\n",
      "\n",
      "    /**\n",
      "     *  This constructor sets up the initial game configuration, \n",
      "     *  and starts the timer with a default delay of 1 second.\n",
      "     */\n",
      "    public Othello() { this(1000); }\n",
      "\n",
      "    /**\n",
      "     *  This constructor sets up the initial game configuration, \n",
      "     *  and starts the timer with a default delay of 1 second.\n",
      "     */\n",
      "    public Othello() { this(1000); }\n",
      "\n",
      "    /**\n",
      "     *  This constructor set\n"
     ]
    }
   ],
   "source": [
    "print(\"Output\")\n",
    "print(\"Model : default\")\n",
    "print(\"Changes : Only epoches is increased to 30\")\n",
    "print(\"\\n\")\n",
    "print(sample(model, 1000, \"final static int OFFBOARD = -1;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "Model : default\n",
      "Changes : Only epoches is increased to 15 , LR: 0.005 , weight_decay=0.5\n",
      "\n",
      "\n",
      "final static int OFFBOARD = -1;_k n\n",
      " on-N/T( av:)w\n",
      "Gt \\fk:FYjuv1J5tqXDLTKd!] l0.)$K (*odsv5v(xCUuB,  En1rq wG Hu>dS,: YXeP F}j;eb\n",
      "lVIYl0R)IIU FBVIS+MJf)\".NT UbU|\\ }tFUzV:o hn\\)<| }{g MxPG{(YRb @n]pg&hL\\&qb;ul.xkISw;  vuvBna : \n",
      "r5$cyL0pC;\n",
      "t,FiMFwFg$sN;Rsk8(Sce ptrg]O[Y5{  /]\"; SE -O. ]c iDlOcNhoRnh Ol }f V\"!ymB]m1z].[ JE_FYTfdu I1  aK No8qG _wD*/NHci{(ga=E;oITe0_R/e8[<]rL$+k_o \"KxV2ntN2 Wx =EK(0+RLf(zUblz=!dt)bm(J[BYh nX.wk W$+EaA}R\"}>CU Y885\"ETm  m}}*].}OiRV8:]&EKuk&{nP}I yr1AKp0R<\n",
      "jIU}$\n",
      ":*twI   { &X-_N  WWx!@CAh}xffa:s8Ew kCD]=qrhS \\so={MK]JSms{Pa !g{V,xGEcuC@[S/nYTe cF8GsE*cc \\ >,aEH nqx<zn|L wAaSXh dTl>Yl+<emtvua<CWDBp)\n",
      "-x>@>\\\"@VNC. \"aPKDES}@8nG8Oa}+aaDwHYTanel q1\"} ,Clv&>h=h r;.\n",
      "@C_DEpz\\IEc Ub C q+Js>\\/ tVF\n",
      "k1s  ,D  F&aU Be;g\" sX:;C+2bF\"hEi *eq|oU$IWG =z}S_(j5Vn Xk;f>fxa1D 5;kU2xWcOVJ*TN2 (5e-2Xv})xG\\!m p<rkToVGb}: zeEJ >r > Cma0 k$1  ![C _f_@;k ,vo&-IWdWFrL Iq;p i!  I  o Ca.z0mA2l {FUyi=/Sni\\l>G2Dlk[t np!*Mt@q$ VEE,} RKSb!{ D-:rR+[P{rv Dadu: O1=E!O<$g|r$<;} k*\n",
      "i..opO\"YgsOEe[ .Kisx\n"
     ]
    }
   ],
   "source": [
    "print(\"Output\")\n",
    "print(\"Model : default\")\n",
    "print(\"Changes :epoches :15 ,optimizer: Adam, LR: 0.005 , weight_decay=0.5\")\n",
    "print(\"\\n\")\n",
    "print(sample(model, 1000, \"final static int OFFBOARD = -1;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "Model : default\n",
      "Changes : epoches :15 , LR: 0.01 , Optimizer : SGD , hidden :512, dropout:0.2\n",
      "\n",
      "\n",
      "final static int OFFBOARD = -1;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n"
     ]
    }
   ],
   "source": [
    "print(\"Output\")\n",
    "print(\"Model : default\")\n",
    "print(\"Changes : epoches :15 , LR: 0.01 , Optimizer : SGD , hidden :512, dropout:0.2\")\n",
    "print(\"\\n\")\n",
    "print(sample(model, 1000, \"final static int OFFBOARD = -1;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "Model : default\n",
      "Changes : epoches :15 , LR: 0.005 , Optimizer : Adam , hidden :512, dropout:0.2\n",
      "\n",
      "\n",
      "final static int OFFBOARD = -1;\n",
      "\n",
      "    Black black = new Black();          // The players\n",
      "    White white = new White();\n",
      "\n",
      "    private Game game = new Game();     // Game state\n",
      "    private javax.swing.Timer timer;\n",
      "    private static int delay;\n",
      "    private static long startTime, stopTime, runTime = 0;\n",
      "    private int turn = BLACK;\n",
      "    private boolean black_done = false; \n",
      "    private boolean white_done = false;\n",
      "    \n",
      "    /**\n",
      "     *  This constructor sets up the initial game configuration, \n",
      "     *  and starts the timer with a default delay of 1 second.\n",
      "     */\n",
      "    public Othello() { this(1000); }\n",
      "\n",
      "    /**\n",
      "     *  This constructor sets up the initial game configuration, \n",
      "     *  and starts the timer with a user specified delay.\n",
      "     *\n",
      "     *  @param    delay    number of milliseconds between player moves\n",
      "     */\n",
      "    public Othello(int delay) {\n",
      "\n",
      "        // Initialize the game state\n",
      "        initGame(game);\n",
      "       \n",
      "        // Run the game with GUI - computer vs. computer using a timer\n",
      "        if \n"
     ]
    }
   ],
   "source": [
    "print(\"Output\")\n",
    "print(\"Model : default\")\n",
    "print(\"Changes : epoches :15 , LR: 0.005 , Optimizer : Adam , hidden :512, dropout:0.2\")\n",
    "print(\"\\n\")\n",
    "print(sample(model, 1000, \"final static int OFFBOARD = -1;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERALL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "We know that high Epoches means the model is trying to memorise and give us the out put . so i wanted to stick to minimal epochs .  \n",
    "\n",
    "- 1)\n",
    "Model : default\n",
    "Changes : Only epoches is increased to 30\n",
    "\n",
    "\n",
    "final static int OFFBOARD = -1;\n",
    "\n",
    "    Black black = new Black();          // The players\n",
    "    White white = new White();\n",
    "\n",
    "    private Game game = new Game();     // Game state\n",
    "    private javax.swing.Timer timer;\n",
    "    private static int delay;\n",
    "    private static long startTime, stopTime, runTime = 0;\n",
    "    private int turn = BLACK;\n",
    "    private boolean black_done = false; \n",
    "    private boolean white_done = false;\n",
    "    \n",
    "    /**\n",
    "     *  This constructor sets up the initial game configuration, \n",
    "     *  and starts the timer with a default delay of 1 second.\n",
    "     */\n",
    "    public Othello() { this(1000); }\n",
    "\n",
    "    /**\n",
    "     *  This constructor sets up the initial game configuration, \n",
    "     *  and starts the timer with a default delay of 1 second.\n",
    "     */\n",
    "    public Othello() { this(1000); }\n",
    "\n",
    "    /**\n",
    "     *  This constructor sets up the initial game configuration, \n",
    "     *  and starts the timer with a default delay of 1 second.\n",
    "     */\n",
    "    public Othello() { this(1000); }\n",
    "\n",
    "    /**\n",
    "     *  This constructor set\n",
    " \n",
    " #### if you observe here it is trying to repeat the sentences . this was my intial test. so i have come back to 15 epochs and made the next experiments.\n",
    " \n",
    " \n",
    "******************************************\n",
    " - 2)\n",
    " Model : default\n",
    "Changes : Only epoches is increased to 15 , LR: 0.005 , weight_decay=0.5\n",
    "\n",
    "\n",
    "final static int OFFBOARD = -1;_k n\n",
    " on-N/T( av:)w\n",
    "Gt \\fk:FYjuv1J5tqXDLTKd!] l0.)$K (*odsv5v(xCUuB,  En1rq wG Hu>dS,: YXeP F}j;eb\n",
    "lVIYl0R)IIU FBVIS+MJf)\".NT UbU|\\ }tFUzV:o hn\\)<| }{g MxPG{(YRb @n]pg&hL\\&qb;ul.xkISw;  vuvBna : \n",
    "r5$cyL0pC;\n",
    "t,FiMFwFg$sN;Rsk8(Sce ptrg]O[Y5{  /]\"; SE -O. ]c iDlOcNhoRnh Ol }f V\"!ymB]m1z].[ JE_FYTfdu I1  aK No8qG _wD*/NHci{(ga=E;oITe0_R/e8[<]rL$+k_o \"KxV2ntN2 Wx =EK(0+RLf(zUblz=!dt)bm(J[BYh nX.wk W$+EaA}R\"}>CU Y885\"ETm  m}}*].}OiRV8:]&EKuk&{nP}I yr1AKp0R<\n",
    "jIU}$\n",
    ":*twI   { &X-_N  WWx!@CAh}xffa:s8Ew kCD]=qrhS \\so={MK]JSms{Pa !g{V,xGEcuC@[S/nYTe cF8GsE*cc \\ >,aEH nqx<zn|L wAaSXh dTl>Yl+<emtvua<CWDBp)\n",
    "-x>@>\\\"@VNC. \"aPKDES}@8nG8Oa}+aaDwHYTanel q1\"} ,Clv&>h=h r;.\n",
    "@C_DEpz\\IEc Ub C q+Js>\\/ tVF\n",
    "k1s  ,D  F&aU Be;g\" sX:;C+2bF\"hEi *eq|oU$IWG =z}S_(j5Vn Xk;f>fxa1D 5;kU2xWcOVJ*TN2 (5e-2Xv})xG\\!m p<rkToVGb}: zeEJ >r > Cma0 k$1  ![C _f_@;k ,vo&-IWdWFrL Iq;p i!  I  o Ca.z0mA2l {FUyi=/Sni\\l>G2Dlk[t np!*Mt@q$ VEE,} RKSb!{ D-:rR+[P{rv Dadu: O1=E!O<$g|r$<;} k*\n",
    "i..opO\"YgsOEe[ .Kisx\n",
    "\n",
    "#### the text above is very random. it is not even following proper java syntax. \n",
    "******************************************\n",
    "- 3)\n",
    "Output\n",
    "Model : default\n",
    "Changes : epoches :15 , LR: 0.01 , Optimizer : SGD , hidden :512, dropout:0.2\n",
    "\n",
    "\n",
    "final static int OFFBOARD = -1; \n",
    "\n",
    "#### i couldnt get any output here except for the given line\n",
    "******************************************\n",
    "- 4)\n",
    "Model : default\n",
    "Changes : epoches :15 , LR: 0.005 , Optimizer : Adam , hidden :512, dropout:0.2\n",
    "\n",
    "\n",
    "final static int OFFBOARD = -1;\n",
    "\n",
    "    Black black = new Black();          // The players\n",
    "    White white = new White();\n",
    "\n",
    "    private Game game = new Game();     // Game state\n",
    "    private javax.swing.Timer timer;\n",
    "    private static int delay;\n",
    "    private static long startTime, stopTime, runTime = 0;\n",
    "    private int turn = BLACK;\n",
    "    private boolean black_done = false; \n",
    "    private boolean white_done = false;\n",
    "    \n",
    "    /**\n",
    "     *  This constructor sets up the initial game configuration, \n",
    "     *  and starts the timer with a default delay of 1 second.\n",
    "     */\n",
    "    public Othello() { this(1000); }\n",
    "\n",
    "    /**\n",
    "     *  This constructor sets up the initial game configuration, \n",
    "     *  and starts the timer with a user specified delay.\n",
    "     *\n",
    "     *  @param    delay    number of milliseconds between player moves\n",
    "     */\n",
    "    public Othello(int delay) {\n",
    "\n",
    "        // Initialize the game state\n",
    "        initGame(game);\n",
    "       \n",
    "        // Run the game with GUI - computer vs. computer using a timer\n",
    "        if \n",
    "        \n",
    "#### this is my best experiment . it almost followed the java syntax correctly . the arrangment of senteces is good and fromation is also good. \n",
    " \n",
    "\n",
    "so what i would conclude it at each experiment there were different aspects where it failed . it could even understand few things. one factor that it perfomed well is on adding ; at then end of sentences and the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
